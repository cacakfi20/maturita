{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from text_processing import preprocess_text\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_excel('../text_data/data.xlsx', nrows=7600, sheet_name='list_update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tokenize and preprocess the text\n",
    "texts = df['text'].astype(str).apply(preprocess_text).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3795, 37)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences)\n",
    "print(data.shape)\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['id'].values\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "with open('encoder.pickle', 'wb') as handle:\n",
    "    pickle.dump(encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 90\n",
    "LSTM1 = 80\n",
    "LSTM2 = 90\n",
    "optimalizer = 'adam'\n",
    "batch_size = 2\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "EMBEDDING_DIM = embedding_dim\n",
    "MAX_LEN = len(data[0])\n",
    "print(MAX_LEN)\n",
    "OUTPUT_CLASSES = len(y_train[0])\n",
    "print(OUTPUT_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN))\n",
    "model.add(LSTM(LSTM1, return_sequences=True))  # Změna na True pro více vrstev LSTM\n",
    "model.add(Dropout(0.5))  # Přidání Dropout vrstvy\n",
    "model.add(LSTM(LSTM2))  # Další vrstva LSTM\n",
    "model.add(Dropout(0.5))  # Přidání Dropout vrstvy\n",
    "model.add(Dense(OUTPUT_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimalizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1328/1328 [==============================] - 36s 25ms/step - loss: 3.0301 - accuracy: 0.1608 - val_loss: 2.2970 - val_accuracy: 0.3494\n",
      "Epoch 2/8\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 1.7006 - accuracy: 0.4913 - val_loss: 1.4351 - val_accuracy: 0.5874\n",
      "Epoch 3/8\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.8617 - accuracy: 0.7361 - val_loss: 1.1470 - val_accuracy: 0.6857\n",
      "Epoch 4/8\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.5376 - accuracy: 0.8392 - val_loss: 1.1085 - val_accuracy: 0.7208\n",
      "Epoch 5/8\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.3451 - accuracy: 0.8961 - val_loss: 1.1412 - val_accuracy: 0.7287\n",
      "Epoch 6/8\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.2442 - accuracy: 0.9236 - val_loss: 1.0730 - val_accuracy: 0.7454\n",
      "Epoch 7/8\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.1943 - accuracy: 0.9375 - val_loss: 1.2025 - val_accuracy: 0.7436\n",
      "Epoch 8/8\n",
      "1328/1328 [==============================] - 32s 24ms/step - loss: 0.1414 - accuracy: 0.9499 - val_loss: 1.3100 - val_accuracy: 0.7375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x212815f1850>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,  # Zvýšení počtu epoch\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: text_model_cz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: text_model_cz\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('text_model_cz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "from text_processing import preprocess_text\n",
    "model = load_model('./text_model_cz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n",
      "vzpírání\n",
      "jistota: 94.14280652999878 %\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from text_processing import preprocess_text\n",
    "class_names = [\"lukostřelba\", \"baseball\", \"basketbal\", \"kulečník\", \"bmx\", \"bowling\", \"box\", \"jízda na býku\", \"roztleskávání\", \"curling\", \"šerm\", \"krasobruslení\", \"fotbal\", \"závody formule 1\", \"golf\", \"skok do výšky\", \"hokej\", \"dostihy\", \"hydroplánové závody\", \"judo\", \"motocyklové závody\", \"pole dance\", \"rugby\", \"skoky na lyžích\", \"snowboarding\", \"rychlobruslení\", \"surfování\", \"plavání\", \"stolní tenis\", \"tenis\", \"dráhové kolo\", \"volejbal\", \"vzpírání\"]\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "with open('encoder.pickle', 'rb') as handle:\n",
    "    encoder = pickle.load(handle)\n",
    "    string = preprocess_text('je aktivita, kde sportovci používají luk k míření a střelbě na terči.')\n",
    "sequences = tokenizer.texts_to_sequences([string])\n",
    "data = pad_sequences(sequences, maxlen=37)\n",
    "predictions = model.predict(data)\n",
    "predicted_labels = predictions.argmax(axis=-1)\n",
    "predicted_labels = encoder.inverse_transform(predicted_labels)\n",
    "predicted_confidence = predictions.max(axis=-1)\n",
    "print(class_names[predicted_labels[0]])\n",
    "print(f\"jistota: {predicted_confidence[0]*100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
