{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from text_processing import preprocess_text\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_excel('../data.xlsx', nrows=3800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tokenize and preprocess the text\n",
    "texts = df['text'].astype(str).apply(preprocess_text).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer() \n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "data = pad_sequences(sequences)\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['id'].values\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "with open('encoder.pickle', 'wb') as handle:\n",
    "    pickle.dump(encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 90\n",
    "LSTM1 = 80\n",
    "LSTM2 = 90\n",
    "optimalizer = 'adam'\n",
    "batch_size = 2\n",
    "epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
    "EMBEDDING_DIM = embedding_dim\n",
    "MAX_LEN = len(data[0])\n",
    "OUTPUT_CLASSES = len(y_train[0])\n",
    "print(OUTPUT_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN))\n",
    "model.add(LSTM(LSTM1, return_sequences=True))  # Změna na True pro více vrstev LSTM\n",
    "model.add(Dropout(0.5))  # Přidání Dropout vrstvy\n",
    "model.add(LSTM(LSTM2))  # Další vrstva LSTM\n",
    "model.add(Dropout(0.5))  # Přidání Dropout vrstvy\n",
    "model.add(Dense(OUTPUT_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimalizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1328/1328 [==============================] - 79s 54ms/step - loss: 2.5549 - accuracy: 0.2861 - val_loss: 1.0869 - val_accuracy: 0.7243\n",
      "Epoch 2/8\n",
      "1328/1328 [==============================] - 72s 54ms/step - loss: 0.7082 - accuracy: 0.7922 - val_loss: 0.4212 - val_accuracy: 0.8841\n",
      "Epoch 3/8\n",
      "1328/1328 [==============================] - 85s 64ms/step - loss: 0.2946 - accuracy: 0.9179 - val_loss: 0.3218 - val_accuracy: 0.9104\n",
      "Epoch 4/8\n",
      "1328/1328 [==============================] - 87s 66ms/step - loss: 0.2010 - accuracy: 0.9413 - val_loss: 0.3077 - val_accuracy: 0.9104\n",
      "Epoch 5/8\n",
      "1328/1328 [==============================] - 89s 67ms/step - loss: 0.1365 - accuracy: 0.9623 - val_loss: 0.3242 - val_accuracy: 0.9175\n",
      "Epoch 6/8\n",
      "1328/1328 [==============================] - 84s 64ms/step - loss: 0.1157 - accuracy: 0.9639 - val_loss: 0.4109 - val_accuracy: 0.9052\n",
      "Epoch 7/8\n",
      "1328/1328 [==============================] - 72s 54ms/step - loss: 0.0839 - accuracy: 0.9725 - val_loss: 0.3123 - val_accuracy: 0.9210\n",
      "Epoch 8/8\n",
      "1328/1328 [==============================] - 71s 53ms/step - loss: 0.0727 - accuracy: 0.9759 - val_loss: 0.4343 - val_accuracy: 0.9025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e90a429e40>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,  # Zvýšení počtu epoch\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_28_layer_call_fn, lstm_cell_28_layer_call_and_return_conditional_losses, lstm_cell_29_layer_call_fn, lstm_cell_29_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: text_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: text_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('text_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.models import load_model\n",
    "model = load_model('../text_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n",
      "surfování\n",
      "jistota: 23.122380673885345 %\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"lukostřelba\", \"baseball\", \"basketbal\", \"kulečník\", \"bmx\", \"bowling\", \"box\", \"jízda na býku\", \"roztleskávání\", \"curling\", \"šerm\", \"krasobruslení\", \"fotbal\", \"závody formule 1\", \"golf\", \"skok do výšky\", \"hokej\", \"dostihy\", \"hydroplánové závody\", \"judo\", \"motocyklové závody\", \"pole dance\", \"rugby\", \"skoky na lyžích\", \"snowboarding\", \"rychlobruslení\", \"surfování\", \"plavání\", \"stolní tenis\", \"tenis\", \"dráhové kolo\", \"volejbal\", \"vzpírání\"]\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "with open('encoder.pickle', 'rb') as handle:\n",
    "    encoder = pickle.load(handle)\n",
    "string = preprocess_text('rugby se hraje na trávě')\n",
    "sequences = tokenizer.texts_to_sequences([string])\n",
    "data = pad_sequences(sequences, maxlen=28)\n",
    "predictions = model.predict(data)\n",
    "predicted_labels = predictions.argmax(axis=-1)\n",
    "predicted_labels = encoder.inverse_transform(predicted_labels)\n",
    "predicted_confidence = predictions.max(axis=-1)\n",
    "print(class_names[predicted_labels[0]])\n",
    "print(f\"jistota: {predicted_confidence[0]*100} %\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
